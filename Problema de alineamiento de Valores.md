Los objetivos/valores de los [[Agente Racional|agentes]] deben estar alineados con los objetivos/valores humanos.
***
La dimensión de este problema se observa en que es difícil saber de antemano los objetivos de lo que perseguimos (muchas veces, son objetivos contradictorios) y las decisiones que pueda tomar un agente con objetivos vagos/no alineados pueden ser peligrosas, sin dejar de ser racionales. 